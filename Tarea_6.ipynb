{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 6\n",
    "\n",
    "Eddson Sierra\n",
    "\n",
    "09/04/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## np.array vs np.matrix\n",
    "\n",
    "**Ejercicio**: Investigar y ejemplificar diferencias entre np.array y np.matrix\n",
    "\n",
    "**Array** permite crear arreglos a partir de listas, secuencias u otros objetos. Es una función más general que **matrix.**\n",
    "\n",
    "*Argumentos de numpy.array*: numpy.array(object, dtype=None, *, copy=True, order='K', subok=False, ndmin=0, like=None)\n",
    "\n",
    "En el caso de **matrix** es una función que permite la creación de matrices o arreglos a partir de elementos diferentes como listas y otros objetos. La gran diferencia es que np.matrix solo permite crear matrices de 2D mientras que np.array permite la creación de arreglos N-dimensionales. La función matrix es una subclase de los ndarrays. Se recomienda el uso de np.array en lugar de np.matrix ya que en el futuro esta última será removida.\n",
    "\n",
    "Ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4]), matrix([[1, 2, 3, 4]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la gran diferencia es que aunque tanto el arreglo como la matriz se crean con el mismo objeto\n",
    "# no tienen las mismas dimensiones ni son del mismo tipo:\n",
    "arr = np.array([1,2,3,4])\n",
    "mat = np.matrix([1,2,3,4])\n",
    "arr, mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del array: (4,) Shape de la matriz: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape del array:\", arr.shape, \"Shape de la matriz:\",mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type del array: <class 'numpy.ndarray'> Type de la matriz: <class 'numpy.matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type del array:\", type(arr), \"Type de la matriz:\",type(mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ambas tienen un método .T para obtener la matriz traspuesta, pero solo matrix tiene .I (matriz inversa) y .H (Conjugada de la matriz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 3]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "arr2 = np.array([[1,2],[3,4]])\n",
    "print(arr2)\n",
    "print(arr2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 3]\n",
      " [2 4]]\n",
      "[[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n",
      "[[1 3]\n",
      " [2 4]]\n"
     ]
    }
   ],
   "source": [
    "mat2 = np.matrix([[1,2],[3,4]])\n",
    "print(mat2)\n",
    "print(mat2.T)\n",
    "print(mat2.I)\n",
    "print(mat2.H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ambas pueden ser convertidas entre sí utilizando np.asmatrix() o np.asarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_from_arr2 = np.asmatrix(arr2)\n",
    "matriz_from_arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_from_mat2 = np.asarray(mat2)\n",
    "arr_from_mat2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio de Valor esperado\n",
    "**Ejemplo en DS** : en inteligencia artificial y ML en la sub-rama \"reinforcement learning\" la \"ecuacion de bellman\" puede aplicarse de manera vectorizada a traves del operar vectores, matrices y escalares en una sola expresión.\n",
    "\n",
    "<img src=\"https://rebornhugo.github.io/assets/images/post_images/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A02/bellman%20equation2.PNG\" width = \"400\" >\n",
    "\n",
    "* n = número de estados del sistema.\n",
    "* V(s) = vector que representa el valor esperado para cierto estado\n",
    "* R = recompensa inmediata percibida por el agente al salir de cierto estado.(vector)\n",
    "* P = matriz de transicion de la cadena de Markov sub-yacente.(matriz)\n",
    "* γ = factor de descuento de recompensas futuras(escalar)\n",
    "\n",
    "Calcular V(s) para el siguiente sistema aplicando la ecuación de bellman de manera vectorizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.array([0,0,0]) # valor inicial de V(s)\n",
    "R = np.array([10,2,5]) # vector de recompensas\n",
    "P = np.array([[0.5,0.25,0.25],\n",
    "              [0.2,0.40,0.40],\n",
    "              [0.80,0.10,0.10]])  # matriz de transición\n",
    "gamma = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.298175, 13.367675, 20.228675])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = R + gamma*np.matmul(P,V)\n",
    "V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio de Neural Network\n",
    "\n",
    "Se tiene una red neuronal sencilla(y simplificada) como la de la siguiente imagen:\n",
    "<img src=\"https://www.oreilly.com/library/view/practical-convolutional-neural/9781788392303/assets/246151fb-7893-448d-b9bb-7a87b387a24b.png\" width=\"300\">\n",
    "\n",
    "Donde:\n",
    "* INPUT LAYER: un vector X de tamaño = 2 que representa los datos de entrada\n",
    "* HIDDEN_LAYER :capa oculta con 2 neuronas definidas por los vectores:\n",
    "    * HL1 = [0.25,0.37]\n",
    "    * HL2 = [-8,14]\n",
    "* OUTPUT_LAYER = capa de salida definida por el vector [4,9]\n",
    "\n",
    "Crear una funcion neural_network(X) para calcular:\n",
    "* Calcule la salida de cada neurona en la capa intermedia aplicada a la capa de entrada.\n",
    "* Use el resultado del paso anterior como entrada para la neurona en la capa de salida\n",
    "\n",
    "Utilizando multiplicación de matrices se debe calcular para cada fila de la matriz de entrada X el valor de las neuronas de la capa intermedia, esto producirá una nueva matriz con el mismo número de filas que X y 2 columnas(1 para cada neurona) , a  los valores de esta matriz se les debe aplicar la función \"sigmoid\"(descrita a continuación) para limitarlos al intervalo de 0 a 1, esto produce una matriz del mismo tamaño pero con valores entre 0 a 1, esta matriz se multiplica matricialmente por la matriz que representa los pesos de la capa de salida  y este proceso produce un nuevo tensor al cual se debe aplicar nuevamente la función sigmoid. El resultado debe ser un tensor con el mismo número de filas que la matriz X y una sola columna(una predicción para cada fila de X.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*Xu7B5y9gp0iL5ooBj7LtWw.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): #convertir los valores de x al rango de 0 a 1\n",
    "    \n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99995577]\n",
      " [0.99999332]]\n"
     ]
    }
   ],
   "source": [
    "H1_W = np.array([[0.25,-8],\n",
    "                 [0.37,14]])\n",
    "OL_W = np.array([[4],[9]])\n",
    "\n",
    "X =  np.array([[0.1,0.2],\n",
    "               [1,2]])\n",
    "\n",
    "H1 = np.matmul(X,H1_W)\n",
    "H1 = sigmoid(H1)  # funcion de activacion: convertir a valores en el intervalo de 0 a 1\n",
    "OL = np.matmul(H1,OL_W)\n",
    "OL = sigmoid(OL)  # funcion de activacion: convertir a valores en el intervalo de 0 a 1\n",
    "\n",
    "print(OL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(X):\n",
    "    HL = np.matmul(X,H1_W)\n",
    "    salida = np.matmul(sigmoid(HL),OL_W)\n",
    "    return sigmoid(salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99995577],\n",
       "       [0.99999332]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network de 3 neuronas HL y función ReLu \n",
    "\n",
    "Implementar en una funcion neural_network(X) la red neuronal definida por la siguiente arquitectura:\n",
    "\n",
    "<img src=\"http://i.imgur.com/UNlffE1.png\" width=\"300\">\n",
    "\n",
    "Podemos validar si fue correctamente implementada si usamos como entrada el vector x=[1,1] . Debemos obtener el resultado mostrado en la imagen.\n",
    "\n",
    "Una vez tenemos la implementacion correcta, cambiar la funcion de activacion de la capa de salida por la funcion de activacion ReLu(https://en.wikipedia.org/wiki/Rectifier_(neural_networks)):\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*DfMRHwxY1gyyDmrIAd-gjQ.png\" width=\"300\">\n",
    "\n",
    "Luego evaluar la red neuronal sobre la matriz de datos X(de manera vectorizada):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0.1,2],\n",
    "    [0.3,0.45],\n",
    "    [5,9],\n",
    "    [12,6],\n",
    "    [7,5],\n",
    "    [0.3,0.8],\n",
    "    [12,5],\n",
    "    [100,200],\n",
    "    [7,8],\n",
    "    [300,1500]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network2(X):  \n",
    "    HL_M = np.array([[0.712, 0.355, 0.268],[0.112, 0.855, 0.468]]) \n",
    "    OUT_M = np.array([[0.116], [0.329], [0.708]])\n",
    "    HL = np.matmul(X, HL_M)\n",
    "    salida = np.matmul(sigmoid(HL),OUT_M)\n",
    "    return sigmoid(salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69269553])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comprobar que la función es correcta según la imagen\n",
    "neural_network2(np.array([1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear funcion de activacion ReLu\n",
    "def ReLu(x):\n",
    "    return np.log(1+ np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modificar la funcion de red neuronal\n",
    "def neural_network2(X):  \n",
    "    HL_M = np.array([[0.712, 0.355, 0.268],[0.112, 0.855, 0.468]]) \n",
    "    OUT_M = np.array([[0.116], [0.329], [0.708]])\n",
    "    HL = np.matmul(X, HL_M)\n",
    "    salida = np.matmul(sigmoid(HL),OUT_M)\n",
    "    return ReLu(salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.21215865],\n",
       "       [1.08646489],\n",
       "       [1.42435675],\n",
       "       [1.42603146],\n",
       "       [1.41891238],\n",
       "       [1.12076711],\n",
       "       [1.42523032],\n",
       "       [1.42735994],\n",
       "       [1.42514924],\n",
       "       [1.42735994]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network2(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
